nohup: ignoring input
../datasets/trans/small_test.en
skipped 0 empty lines
filtered 0 lines
../datasets/trans/small_spm_mbart.en_XX
tmp (<function setup_registry.<locals>.build_x at 0x7f6ddf452378>, <function setup_registry.<locals>.register_x at 0x7f6ddf4522f0>, {}, {})

2021-07-27 01:51:37 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='../datasets/trans/small_en_XX.spm_mbart.dest', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, simul_type=None, source_lang='en_XX', srcdict='../datasets/trans/dict.en_XX.txt', suppress_crashes=False, target_lang='fr_XX', task='translation', tensorboard_logdir=None, testpref='../datasets/trans/small_spm_mbart', tgtdict='../datasets/trans/dict.en_XX.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=1)
2021-07-27 01:51:39 | INFO | fairseq_cli.preprocess | [en_XX] Dictionary: 250001 types
2021-07-27 01:51:40 | INFO | fairseq_cli.preprocess | [en_XX] ../datasets/trans/small_spm_mbart.en_XX: 200 sents, 72324 tokens, 0.0% replaced by <unk>
2021-07-27 01:51:40 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ../datasets/trans/small_en_XX.spm_mbart.dest
Done preprocess!
/home/work/anaconda3/envs/py3.6/lib/python3.6/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
Done generate!
Done translate!
